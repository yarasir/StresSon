@file:OptIn(androidx.camera.core.ExperimentalGetImage::class)

package com.example.stressdetection.ui.screens

import android.Manifest
import android.content.pm.PackageManager
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.compose.foundation.Canvas
import androidx.compose.foundation.background
import androidx.compose.foundation.layout.*
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.geometry.Offset
import androidx.compose.ui.geometry.Size
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.graphics.drawscope.Stroke
import androidx.compose.ui.platform.LocalContext
import androidx.compose.ui.platform.LocalDensity
import androidx.compose.ui.platform.LocalLifecycleOwner
import androidx.compose.ui.unit.dp
import androidx.compose.ui.viewinterop.AndroidView
import androidx.core.content.ContextCompat
import com.example.stressdetection.analyzer.StressImageAnalyzer
import com.example.stressdetection.model.FaceDetectionResult
import com.example.stressdetection.model.StressLevel
import com.example.stressdetection.ui.components.StressLevelIndicatorSimple
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.delay
import kotlinx.coroutines.withContext
import java.util.concurrent.Executors

@Composable
fun StressDetectionScreen(requestPermission: (String) -> Unit, onBack: () -> Unit) {
    val context = LocalContext.current
    var stressLevel by remember { mutableStateOf<StressLevel?>(null) }
    var hasPermission by remember {
        mutableStateOf(
            ContextCompat.checkSelfPermission(
                context,
                Manifest.permission.CAMERA
            ) == PackageManager.PERMISSION_GRANTED
        )
    }

    // Ä°zin durumunu kontrol et
    LaunchedEffect(Unit) {
        val currentPermission = ContextCompat.checkSelfPermission(
            context,
            Manifest.permission.CAMERA
        ) == PackageManager.PERMISSION_GRANTED
        hasPermission = currentPermission
        if (!hasPermission) {
            android.util.Log.d("StressDetection", "Kamera izni isteniyor...")
            requestPermission(Manifest.permission.CAMERA)
        } else {
            android.util.Log.d("StressDetection", "âœ… Kamera izni mevcut")
        }
    }
    
    // Ä°zin durumunu periyodik olarak kontrol et
    LaunchedEffect(Unit) {
        while (true) {
            delay(500) // Her 500ms'de bir kontrol et
            val currentPermission = ContextCompat.checkSelfPermission(
                context,
                Manifest.permission.CAMERA
            ) == PackageManager.PERMISSION_GRANTED
            if (currentPermission != hasPermission) {
                hasPermission = currentPermission
                android.util.Log.d("StressDetection", "Ä°zin durumu gÃ¼ncellendi: $hasPermission")
            }
        }
    }

    Column(
        modifier = Modifier
            .fillMaxSize()
            .background(Color.Black)
    ) {
        Box(modifier = Modifier.weight(1f)) {
            if (hasPermission) {
                CameraPreview(
                    onFaceDetected = { result -> 
                        stressLevel = result.stressLevel
                        // Logcat'te duygu durumunu gÃ¶ster
                        android.util.Log.d("StressDetection", "ðŸŽ­ Duygu: ${result.dominantEmotion}, Stres: ${result.stressLevel}")
                    }
                )
            } else {
                Text(
                    "Kamera izni gerekli",
                    color = Color.White,
                    modifier = Modifier.align(Alignment.Center)
                )
            }
            Button(
                onClick = onBack,
                modifier = Modifier.padding(16.dp).align(Alignment.TopStart)
            ) {
                Text("Geri")
            }
        }
        StressLevelIndicatorSimple(stressLevel, modifier = Modifier.padding(16.dp))
    }
}

@Composable
fun CameraPreview(onFaceDetected: (FaceDetectionResult) -> Unit) {
    val context = LocalContext.current
    val lifecycleOwner = LocalLifecycleOwner.current
    val previewView = remember { PreviewView(context) }
    val analyzerExecutor = remember { Executors.newSingleThreadExecutor() }
    var faceResults by remember { mutableStateOf<List<FaceDetectionResult>>(emptyList()) }

    LaunchedEffect(Unit) {
        try {
            android.util.Log.d("CameraPreview", "ðŸ“· Kamera baÅŸlatÄ±lÄ±yor...")
            val cameraProviderFuture = ProcessCameraProvider.getInstance(context)
            
            // Kamera provider'Ä± arka thread'de bekle
            val cameraProvider = withContext(Dispatchers.IO) {
                cameraProviderFuture.get()
            }
            
            val preview = Preview.Builder()
                .build()
                .also {
                    it.setSurfaceProvider(previewView.surfaceProvider)
                }

            val analyzer = ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .setOutputImageFormat(ImageAnalysis.OUTPUT_IMAGE_FORMAT_YUV_420_888)
                .build()
                .also {
                    it.setAnalyzer(
                        analyzerExecutor,
                        StressImageAnalyzer(context) { results ->
                            faceResults = results
                            // Ä°lk yÃ¼zÃ¼ callback'e gÃ¶nder (stres seviyesi iÃ§in)
                            if (results.isNotEmpty()) {
                                onFaceDetected(results[0])
                            }
                        }
                    )
                }

            cameraProvider.unbindAll()
            
            // EmÃ¼latÃ¶rde lens facing bilgisi olmayabilir, bu yÃ¼zden Ã¶nce DEFAULT kamera dene
            val cameraSelector = try {
                android.util.Log.d("CameraPreview", "ðŸ“· Ã–n kamera deneniyor...")
                cameraProvider.bindToLifecycle(
                    lifecycleOwner,
                    CameraSelector.DEFAULT_FRONT_CAMERA,
                    preview,
                    analyzer
                )
                android.util.Log.d("CameraPreview", "âœ… Ã–n kamera baÅŸarÄ±yla baÄŸlandÄ±")
                CameraSelector.DEFAULT_FRONT_CAMERA
            } catch (e: Exception) {
                android.util.Log.w("CameraPreview", "Ã–n kamera bulunamadÄ±: ${e.message}")
                try {
                    android.util.Log.d("CameraPreview", "ðŸ“· Arka kamera deneniyor...")
                    cameraProvider.unbindAll()
                    cameraProvider.bindToLifecycle(
                        lifecycleOwner,
                        CameraSelector.DEFAULT_BACK_CAMERA,
                        preview,
                        analyzer
                    )
                    android.util.Log.d("CameraPreview", "âœ… Arka kamera baÅŸarÄ±yla baÄŸlandÄ±")
                    CameraSelector.DEFAULT_BACK_CAMERA
                } catch (e2: Exception) {
                    android.util.Log.w("CameraPreview", "Arka kamera bulunamadÄ±: ${e2.message}")
                    // EmÃ¼latÃ¶r sorunu: Lens facing bilgisi yok
                    android.util.Log.e("CameraPreview", "âŒ EmÃ¼latÃ¶rde kamera kullanÄ±lamÄ±yor")
                    android.util.Log.e("CameraPreview", "ðŸ’¡ Ã‡Ã–ZÃœM ADIMLARI:")
                    android.util.Log.e("CameraPreview", "   1. Android Studio'da AVD Manager'Ä± aÃ§Ä±n")
                    android.util.Log.e("CameraPreview", "   2. EmÃ¼latÃ¶rÃ¼nÃ¼zÃ¼ seÃ§in ve 'Edit' (kalem ikonu) tÄ±klayÄ±n")
                    android.util.Log.e("CameraPreview", "   3. 'Show Advanced Settings' butonuna tÄ±klayÄ±n")
                    android.util.Log.e("CameraPreview", "   4. 'Camera' bÃ¶lÃ¼mÃ¼ne gidin")
                    android.util.Log.e("CameraPreview", "   5. 'Front Camera' ve 'Back Camera' iÃ§in 'Webcam0' veya 'VirtualScene' seÃ§in")
                    android.util.Log.e("CameraPreview", "   6. 'Finish' tÄ±klayÄ±n ve emÃ¼latÃ¶rÃ¼ yeniden baÅŸlatÄ±n")
                    android.util.Log.e("CameraPreview", "")
                    android.util.Log.e("CameraPreview", "   VEYA:")
                    android.util.Log.e("CameraPreview", "   - Video analizi Ã¶zelliÄŸini kullanÄ±n (kamera yerine)")
                    android.util.Log.e("CameraPreview", "   - FarklÄ± bir emÃ¼latÃ¶r deneyin (Pixel 5, Pixel 6)")
                    
                    throw IllegalStateException(
                        "EmÃ¼latÃ¶rde kamera kullanÄ±lamÄ±yor.\n\n" +
                        "Ã‡Ã–ZÃœM:\n" +
                        "1. AVD Manager â†’ EmÃ¼latÃ¶rÃ¼nÃ¼zÃ¼ seÃ§in â†’ Edit\n" +
                        "2. Show Advanced Settings â†’ Camera\n" +
                        "3. Front/Back Camera iÃ§in 'Webcam0' seÃ§in\n" +
                        "4. EmÃ¼latÃ¶rÃ¼ yeniden baÅŸlatÄ±n\n\n" +
                        "VEYA Video analizi Ã¶zelliÄŸini kullanÄ±n."
                    )
                }
            }
        } catch (exc: Exception) {
            android.util.Log.e("CameraPreview", "âŒ Kamera baÅŸlatma hatasÄ±: ${exc.message}", exc)
            android.util.Log.e("CameraPreview", "Hata detayÄ±: ${exc.stackTraceToString()}")
            exc.printStackTrace()
        }
    }

    Box(modifier = Modifier.fillMaxSize()) {
        AndroidView(factory = { previewView }, modifier = Modifier.fillMaxSize())

        // YÃ¼z Ã§erÃ§evesi ve duygu durumu gÃ¶sterimi (TÃœM YÃœZLER)
        faceResults.forEach { result ->
            result.boundingBox?.let { rect ->
                val density = LocalDensity.current
                
                // GerÃ§ek ImageProxy boyutlarÄ±nÄ± kullan (result'tan geliyor)
                val imgWidth = if (result.imageWidth > 0) result.imageWidth.toFloat() else 640f
                val imgHeight = if (result.imageHeight > 0) result.imageHeight.toFloat() else 480f
                
                // Ã‡erÃ§eve Ã§iz (Video analizi gibi: Canvas iÃ§inde scale hesapla)
                Canvas(modifier = Modifier.fillMaxSize()) {
                    if (imgWidth > 0 && imgHeight > 0) {
                        // Video analizi gibi: Canvas boyutunu kullan
                        val scaleX = size.width / imgWidth
                        val scaleY = size.height / imgHeight
                        
                        val left = rect.left * scaleX
                        val top = rect.top * scaleY
                        val width = rect.width() * scaleX
                        val height = rect.height() * scaleY
                        
                        android.util.Log.d("CameraPreview", "ðŸ” Ã‡erÃ§eve Ã§iziliyor: rect=(${rect.left},${rect.top},${rect.right},${rect.bottom}), " +
                                "canvas=${size.width.toInt()}x${size.height.toInt()}, scale=(${String.format("%.2f", scaleX)},${String.format("%.2f", scaleY)}), " +
                                "transformed=(${left.toInt()},${top.toInt()},${width.toInt()},${height.toInt()})")
                        
                        val color = when (result.stressLevel) {
                            StressLevel.HIGH -> Color.Red
                            StressLevel.MEDIUM -> Color.Yellow
                            StressLevel.LOW -> Color.Green
                        }
                        drawRect(
                            color = color,
                            topLeft = Offset(left, top),
                            size = Size(width, height),
                            style = Stroke(width = 5f)
                        )
                    }
                }
                
                // Duygu durumu metni (Video analizi gibi)
                if (imgWidth > 0 && imgHeight > 0) {
                    val previewWidth = previewView.width.toFloat()
                    val previewHeight = previewView.height.toFloat()
                    val scaleX = previewWidth / imgWidth
                    val scaleY = previewHeight / imgHeight
                    
                    Box(
                        modifier = Modifier
                            .offset(
                                x = with(density) { (rect.left * scaleX).toFloat().toDp() },
                                y = with(density) { ((rect.top - 60) * scaleY).toFloat().toDp() }
                            )
                    ) {
                        Column(
                            modifier = Modifier
                                .background(Color.Black.copy(alpha = 0.8f))
                                .padding(8.dp)
                        ) {
                            Text(
                                text = "Duygu: ${result.dominantEmotion}",
                                color = Color.Yellow,
                                style = MaterialTheme.typography.bodySmall
                            )
                            Text(
                                text = "Stres: ${when (result.stressLevel) {
                                    StressLevel.LOW -> "DÃ¼ÅŸÃ¼k"
                                    StressLevel.MEDIUM -> "Orta"
                                    StressLevel.HIGH -> "YÃ¼ksek"
                                }}",
                                color = when (result.stressLevel) {
                                    StressLevel.LOW -> Color(0xFF4CAF50)
                                    StressLevel.MEDIUM -> Color(0xFFFF9800)
                                    StressLevel.HIGH -> Color(0xFFF44336)
                                },
                                style = MaterialTheme.typography.bodySmall
                            )
                        }
                    }
                }
            }
        }
    }
}


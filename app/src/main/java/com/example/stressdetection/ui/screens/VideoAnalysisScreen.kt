package com.example.stressdetection.ui.screens

import android.graphics.Bitmap
import android.media.MediaMetadataRetriever
import android.net.Uri
import android.view.ViewGroup
import android.widget.VideoView
import androidx.compose.foundation.Canvas
import androidx.compose.foundation.background
import androidx.compose.foundation.layout.*
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.ui.Modifier
import androidx.compose.ui.geometry.Offset
import androidx.compose.ui.geometry.Size
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.graphics.drawscope.Stroke
import androidx.compose.ui.platform.LocalContext
import androidx.compose.ui.platform.LocalDensity
import androidx.compose.ui.unit.dp
import androidx.compose.ui.viewinterop.AndroidView
import com.example.stressdetection.analyzer.StressImageAnalyzer
import com.example.stressdetection.model.StressLevel
import com.example.stressdetection.model.VideoFaceResult
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import kotlinx.coroutines.delay
import kotlinx.coroutines.isActive

@Composable
fun VideoAnalysisScreen(videoUri: Uri, onBack: () -> Unit) {
    val context = LocalContext.current
    val analyzer = remember { StressImageAnalyzer(context) }
    var detectedFaces by remember { mutableStateOf<List<VideoFaceResult>>(emptyList()) }
    var videoView: VideoView? by remember { mutableStateOf(null) }
    var videoWidth by remember { mutableStateOf(0) }
    var videoHeight by remember { mutableStateOf(0) }
    var viewWidth by remember { mutableStateOf(0) }
    var viewHeight by remember { mutableStateOf(0) }

    val faceDetector = remember {
        val opts = FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)
            .enableTracking()
            .setMinFaceSize(0.12f) // Biraz daha kÃ¼Ã§Ã¼k yÃ¼zleri de tespit et (0.15 -> 0.12)
            .build()
        FaceDetection.getClient(opts)
    }

    LaunchedEffect(videoView) {
        // âœ… VideoView'un hazÄ±r olmasÄ±nÄ± bekle
        if (videoView == null) return@LaunchedEffect
        
        // âœ… Retriever'Ä± bir kere oluÅŸtur, loop boyunca reuse et
        val retriever = MediaMetadataRetriever().apply {
            try {
                setDataSource(context, videoUri)
                android.util.Log.d("VideoAnalysis", "âœ… Retriever oluÅŸturuldu")
            } catch (e: Exception) {
                android.util.Log.e("VideoAnalysis", "âŒ Retriever setDataSource hatasÄ±: ${e.message}", e)
            }
        }
        
        // âœ… Video baÅŸlamadan Ã¶nce kÄ±sa bir bekleme
        delay(300) // Video baÅŸlamasÄ± iÃ§in bekle
        
        try {
            // âœ… Ä°lk frame'i hemen analiz et
            var isFirstFrame = true
            
            while (isActive && videoView != null && videoView!!.isPlaying) {
                if (!isFirstFrame) {
                    delay(200) // Her 0.2 saniyede bir analiz (daha hÄ±zlÄ± tespit)
                } else {
                    isFirstFrame = false
                }
                try {
                    val timeUs = videoView!!.currentPosition * 1000L
                    val frame = retriever.getFrameAtTime(timeUs, MediaMetadataRetriever.OPTION_CLOSEST)

                    frame?.let { bitmap ->
                        // âœ… KRÄ°TÄ°K: Bitmap boyutlarÄ± ML Kit koordinatlarÄ±nÄ±n referansÄ±dÄ±r
                        // Video boyutlarÄ±nÄ± bitmap'ten al (ML Kit bu boyutlara gÃ¶re koordinat veriyor)
                        val bitmapWidth = bitmap.width
                        val bitmapHeight = bitmap.height
                        
                        // Video boyutlarÄ±nÄ± gÃ¼ncelle (bitmap boyutlarÄ±na gÃ¶re)
                        if (videoWidth == 0 || videoHeight == 0 || 
                            videoWidth != bitmapWidth || videoHeight != bitmapHeight) {
                            videoWidth = bitmapWidth
                            videoHeight = bitmapHeight
                            android.util.Log.d("VideoAnalysis", "ðŸ“ Bitmap boyutlarÄ± (ML Kit referansÄ±): ${bitmapWidth}x${bitmapHeight}")
                        }
                        
                        val inputImage = InputImage.fromBitmap(bitmap, 0)
                        faceDetector.process(inputImage)
                            .addOnSuccessListener { faces ->
                                // âœ… BOÅž LÄ°STE KONTROLÃœ: EÄŸer yÃ¼z yoksa boÅŸ liste dÃ¶ndÃ¼r
                                if (faces.isEmpty()) {
                                    detectedFaces = emptyList()
                                    return@addOnSuccessListener
                                }

                                // âœ… EN BÃœYÃœK YÃœZE ODAKLAN (alanÄ± en bÃ¼yÃ¼k olan)
                                val sortedFaces = faces.sortedByDescending { 
                                    it.boundingBox.width() * it.boundingBox.height() 
                                }
                                
                                val results = mutableListOf<VideoFaceResult>()
                                for (face in sortedFaces) {
                                    try {
                                        // âœ… Bounding box koordinatlarÄ±nÄ± bitmap boyutlarÄ±na gÃ¶re normalize et
                                        val normalizedBox = android.graphics.Rect(
                                            face.boundingBox.left.coerceIn(0, bitmapWidth),
                                            face.boundingBox.top.coerceIn(0, bitmapHeight),
                                            face.boundingBox.right.coerceIn(0, bitmapWidth),
                                            face.boundingBox.bottom.coerceIn(0, bitmapHeight)
                                        )
                                        
                                        val faceBitmap = Bitmap.createBitmap(
                                            bitmap,
                                            normalizedBox.left,
                                            normalizedBox.top,
                                            normalizedBox.width().coerceAtMost(bitmap.width - normalizedBox.left),
                                            normalizedBox.height().coerceAtMost(bitmap.height - normalizedBox.top)
                                        )
                                        val inference = analyzer.runInference(faceBitmap)
                                        results.add(
                                            VideoFaceResult(
                                                normalizedBox, // Normalize edilmiÅŸ bounding box
                                                inference.first,
                                                inference.second
                                            )
                                        )
                                        android.util.Log.d("VideoAnalysis", "ðŸ‘¤ YÃ¼z: box=(${normalizedBox.left},${normalizedBox.top},${normalizedBox.right},${normalizedBox.bottom}), " +
                                                "bitmap=${bitmapWidth}x${bitmapHeight}")
                                    } catch (e: Exception) {
                                        android.util.Log.e("VideoAnalysis", "YÃ¼z iÅŸleme hatasÄ±: ${e.message}")
                                    }
                                }
                                detectedFaces = results
                                android.util.Log.d("VideoAnalysis", "âœ… ${results.size} yÃ¼z iÅŸlendi (en bÃ¼yÃ¼k yÃ¼z Ã¶ncelikli)")
                            }
                            .addOnFailureListener { e ->
                                android.util.Log.e("VideoAnalysis", "YÃ¼z tespiti hatasÄ±: ${e.message}")
                                detectedFaces = emptyList()
                            }
                    }
                } catch (e: Exception) {
                    android.util.Log.e("VideoAnalysis", "Frame analiz hatasÄ±: ${e.message}")
                }
            }
        } finally {
            // âœ… Retriever'Ä± dÃ¼zgÃ¼n kapat
            try {
                retriever.release()
                android.util.Log.d("VideoAnalysis", "âœ… Retriever release edildi")
            } catch (e: Exception) {
                android.util.Log.e("VideoAnalysis", "âŒ Retriever release hatasÄ±: ${e.message}", e)
            }
        }
    }

    Box(
        modifier = Modifier
            .fillMaxSize()
            .background(Color.Black)
    ) {
        AndroidView(
            factory = { ctx ->
                android.widget.VideoView(ctx).apply {
                    layoutParams = ViewGroup.LayoutParams(
                        ViewGroup.LayoutParams.MATCH_PARENT,
                        ViewGroup.LayoutParams.MATCH_PARENT
                    )
                    setVideoURI(videoUri)
                    setOnPreparedListener { mp ->
                        mp.isLooping = true
                        videoWidth = mp.videoWidth
                        videoHeight = mp.videoHeight
                        android.util.Log.d("VideoAnalysis", "Video hazÄ±r: ${mp.videoWidth}x${mp.videoHeight}")
                        android.util.Log.d("VideoAnalysis", "Video aspect ratio: ${videoWidth.toFloat() / videoHeight.toFloat()}")
                        start()
                    }
                    addOnLayoutChangeListener { _, _, _, _, _, _, _, _, _ ->
                        viewWidth = width
                        viewHeight = height
                        android.util.Log.d("VideoAnalysis", "View boyutlarÄ±: ${width}x${height}")
                        android.util.Log.d("VideoAnalysis", "View aspect ratio: ${width.toFloat() / height.toFloat()}")
                    }
                    videoView = this
                }
            },
            modifier = Modifier.fillMaxSize()
        )

        // YÃ¼z overlay - âœ… KOORDINAT DÃ–NÃœÅžÃœMÃœ: Bitmap koordinatlarÄ±nÄ± Canvas koordinatlarÄ±na Ã§evir
        Canvas(modifier = Modifier.fillMaxSize()) {
            if (videoWidth > 0 && videoHeight > 0 && viewWidth > 0 && viewHeight > 0) {
                // âœ… VideoView CENTER_CROP gibi davranÄ±r - aspect ratio korunarak scale
                // Bitmap boyutlarÄ± (videoWidth x videoHeight) -> Canvas boyutlarÄ± (size.width x size.height)
                val bitmapAspect = videoWidth.toFloat() / videoHeight.toFloat()
                val canvasAspect = size.width / size.height
                
                val scaleX: Float
                val scaleY: Float
                val offsetX: Float
                val offsetY: Float
                
                if (bitmapAspect > canvasAspect) {
                    // Bitmap daha geniÅŸ - yÃ¼ksekliÄŸe gÃ¶re scale (CENTER_CROP)
                    // Canvas yÃ¼ksekliÄŸi tamamen doldurulur, geniÅŸlik ortalanÄ±r
                    scaleY = size.height / videoHeight.toFloat()
                    scaleX = scaleY // Aspect ratio korunur
                    offsetX = (size.width - videoWidth * scaleX) / 2f
                    offsetY = 0f
                } else {
                    // Bitmap daha yÃ¼ksek - geniÅŸliÄŸe gÃ¶re scale (CENTER_CROP)
                    // Canvas geniÅŸliÄŸi tamamen doldurulur, yÃ¼kseklik ortalanÄ±r
                    scaleX = size.width / videoWidth.toFloat()
                    scaleY = scaleX // Aspect ratio korunur
                    offsetX = 0f
                    offsetY = (size.height - videoHeight * scaleY) / 2f
                }
                
                detectedFaces.forEach { face ->
                    // âœ… Bitmap koordinatlarÄ±nÄ± Canvas koordinatlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
                    val left = face.boundingBox.left * scaleX + offsetX
                    val top = face.boundingBox.top * scaleY + offsetY
                    val right = face.boundingBox.right * scaleX + offsetX
                    val bottom = face.boundingBox.bottom * scaleY + offsetY
                    val width = right - left
                    val height = bottom - top
                    
                    // âœ… Debug log (sadece ilk yÃ¼z iÃ§in)
                    if (detectedFaces.indexOf(face) == 0) {
                        android.util.Log.d("VideoAnalysis", "ðŸŽ¯ YÃ¼z Ã§erÃ§evesi: " +
                                "Bitmap box=(${face.boundingBox.left},${face.boundingBox.top},${face.boundingBox.right},${face.boundingBox.bottom}), " +
                                "Canvas box=(${left.toInt()},${top.toInt()},${right.toInt()},${bottom.toInt()}), " +
                                "Scale=(${String.format("%.3f", scaleX)},${String.format("%.3f", scaleY)}), " +
                                "Offset=(${offsetX.toInt()},${offsetY.toInt()})")
                    }
                    
                    drawRect(
                        color = when (face.stressLevel) {
                            StressLevel.HIGH -> Color.Red
                            StressLevel.MEDIUM -> Color.Yellow
                            StressLevel.LOW -> Color.Green
                        },
                        topLeft = Offset(left, top),
                        size = Size(width, height),
                        style = Stroke(width = 5f)
                    )
                }
            }
        }

        // YÃ¼z bilgileri - âœ… KOORDINAT DÃ–NÃœÅžÃœMÃœ (Canvas ile aynÄ± mantÄ±k)
        val density = LocalDensity.current
        if (videoWidth > 0 && videoHeight > 0 && viewWidth > 0 && viewHeight > 0) {
            // âœ… Canvas ile aynÄ± hesaplama (tutarlÄ±lÄ±k iÃ§in)
            val bitmapAspect = videoWidth.toFloat() / videoHeight.toFloat()
            val viewAspect = viewWidth.toFloat() / viewHeight.toFloat()
            
            val scaleX: Float
            val scaleY: Float
            val offsetX: Float
            val offsetY: Float
            
            if (bitmapAspect > viewAspect) {
                // Bitmap daha geniÅŸ - yÃ¼ksekliÄŸe gÃ¶re scale
                scaleY = viewHeight.toFloat() / videoHeight.toFloat()
                scaleX = scaleY
                offsetX = (viewWidth - videoWidth * scaleX) / 2f
                offsetY = 0f
            } else {
                // Bitmap daha yÃ¼ksek - geniÅŸliÄŸe gÃ¶re scale
                scaleX = viewWidth.toFloat() / videoWidth.toFloat()
                scaleY = scaleX
                offsetX = 0f
                offsetY = (viewHeight - videoHeight * scaleY) / 2f
            }
            
            detectedFaces.forEach { face ->
                Box(
                    modifier = Modifier
                        .offset(
                            x = with(density) { (face.boundingBox.left * scaleX + offsetX).toFloat().toDp() },
                            y = with(density) { ((face.boundingBox.top - 60) * scaleY + offsetY).toFloat().toDp() }
                        )
                ) {
                    Column(
                        modifier = Modifier
                            .background(Color.Black.copy(alpha = 0.8f))
                            .padding(8.dp)
                    ) {
                        Text(
                            text = "Duygu: ${face.dominantEmotion}",
                            color = Color.Yellow,
                            style = MaterialTheme.typography.bodySmall
                        )
                        Text(
                            text = "Stres: ${when (face.stressLevel) {
                                StressLevel.LOW -> "DÃ¼ÅŸÃ¼k"
                                StressLevel.MEDIUM -> "Orta"
                                StressLevel.HIGH -> "YÃ¼ksek"
                            }}",
                            color = when (face.stressLevel) {
                                StressLevel.LOW -> Color(0xFF4CAF50)
                                StressLevel.MEDIUM -> Color(0xFFFF9800)
                                StressLevel.HIGH -> Color(0xFFF44336)
                            },
                            style = MaterialTheme.typography.bodySmall
                        )
                    }
                }
            }
        }

        Button(onClick = onBack, modifier = Modifier.padding(16.dp)) {
            Text("Geri")
        }
    }
}

